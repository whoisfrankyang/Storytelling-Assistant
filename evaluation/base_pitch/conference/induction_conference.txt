Abstract: INTEGRATING INDUCTIVE AND TRANSDUCTIVE METHODOLOGIES FOR ABSTRACT REASONING OPTIMIZATION

In the process of discerning input-output correlations from minimal instances, the comparative efficacy of preliminary latent function extrapolation versus immediate test output prediction, such as through a neural network, warrants examination. This study investigates this dichotomy utilizing ARC, by training neural configurations for both inductive (latent function inference) and transductive (immediate test output prediction from given input) methodologies. Training is executed on synthetic iterations of Python programs designed to resolve ARC training tasks. Results indicate inductive and transductive models address divergent types of test problems, notwithstanding identical training tasks and shared neural architecture. Inductive program synthesis demonstrates proficiency in precise computations and multi-concept composition, while transduction is more effective with nebulous perceptual concepts. Ensemble models approach human-level ARC performance.