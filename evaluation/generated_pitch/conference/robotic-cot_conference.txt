'''This study addresses a critical challenge in robotic control: the generalization ability of learned robot policies. Our innovative approach introduces Embodied Chain-of-Thought Reasoning (ECoT) into vision-language-action models (VLAs), enabling multiple-step reasoning about plans, sub-tasks, and visually grounded features before predicting robot action. ECoT, leveraging a scalable pipeline for synthetic training data generation, improved the absolute success rate of OpenVLA by 28% on complex generalization tasks, without additional robot training data. It also enhanced human interpretability and interactive correction of policy failures. Despite initial success, the work highlights the need for future research in transferring ECoT reasoning to unseen embodiments and tasks.'''