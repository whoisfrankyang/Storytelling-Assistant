1. improve prompting
2. use better filtering & reranking
  - split large docs into smaller passages (300-500 words)
  - embed passages, not whole docs -> get more fine-grained matches
  - rerank top-k using cross-encoder (cross-encoder/ms-marco-MiniLM-L-6-v2)
3. test the performance of using :
  a. whole docs 
  b. large docs into smaller passages
  c. using only title and abstract

4. hyperparameters tuning
response = client.chat.completions.create(
    model="gpt-4",
    temperature=0.8,  # for creativity
    top_p=0.95,       # nucleus sampling
    max_tokens=700,
    ...
)

